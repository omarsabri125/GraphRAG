# GraphRAG

A powerful Graph-based Retrieval Augmented Generation (RAG) system built with Neo4j, Qdrant vector database, semantic caching, and multiple LLM integrations.

## Overview

GraphRAG combines the power of graph databases with vector search and large language models to create an intelligent knowledge retrieval and generation system. This project leverages Neo4j for graph storage and traversal, Qdrant for hybrid vector search, semantic caching for optimized performance, and integrates with Google Gemini and Cohere LLMs for enhanced question-answering and content generation.

**Arabic Medical Data Support**: This system includes comprehensive medical disease information in Arabic, making it accessible for Arabic-speaking users to query about symptoms, treatments, medications, and disease relationships in their native language.

## Features

- **Graph Database Integration**: Utilizes Neo4j for efficient knowledge graph storage and querying
- **Hybrid Search with Qdrant**: Advanced vector search combining dense and sparse vectors for optimal retrieval
- **Semantic Caching**: Intelligent caching layer that reduces redundant LLM calls and improves response times
- **Multi-LLM Support**: Integration with Google Gemini and Cohere for diverse AI capabilities
- **Multilingual Support**: Powered by Cohere's multilingual capabilities, supporting Arabic and other languages
- **Arabic Medical Knowledge**: Pre-loaded with medical disease data in Arabic for healthcare queries
- **Streamlit Frontend**: Interactive web interface for easy querying and visualization
- **Async Architecture**: Built with Python's asyncio for high-performance operations
- **Vector Embeddings**: Support for multiple embedding models for semantic understanding
- **Template Processing**: Advanced template parsing for dynamic content generation
- **Docker Support**: Containerized deployment for easy setup and scalability

## Project Structure

```
GraphRAG/
├── frontend/                # Streamlit-based user interface
├── graphrag/               # Main application code
│   ├── src/
│   │   ├── controllers/    # API controllers (NLP, Process)
│   │   ├── helpers/        # Utility functions
│   │   ├── models/         # Data models (Neo4j)
│   │   ├── routes/         # API routes
│   │   ├── schemes/        # Data schemas
│   │   └── stores/         # Data storage layers
│   │       ├── llm/        # LLM provider factories
│   │       ├── templates/  # Template parsers
│   │       └── vectordb/   # Vector database providers
│   ├── main.py            # Application entry point
│   └── pipeline.py        # Data processing pipeline
├── GraphRAGDocker/        # Docker configuration
├── requirements.txt       # Python dependencies
└── README.md             # Project documentation
```

## Prerequisites

- Python 3.8+
- [uv](https://github.com/astral-sh/uv) - Fast Python package installer
- Neo4j Database
- Qdrant Vector Database
- Docker (optional, for containerized deployment)
- Google Gemini API Key
- Cohere API Key

## Installation

### Local Setup

1. Clone the repository:
```bash
git clone https://github.com/omarsabri125/GraphRAG.git
cd GraphRAG
```

2. Install dependencies:
```bash
uv pip install -r requirements.txt
```

3. Configure environment variables:
```bash
# Create a .env file with your settings
# Neo4j Configuration
NEO4J_URI=<your-neo4j-uri>
NEO4J_USERNAME=<your-username>
NEO4J_PASSWORD=<your-password>

# Qdrant Configuration
QDRANT_URL=<your-qdrant-url>
QDRANT_API_KEY=<your-qdrant-api-key>

# LLM API Keys
GEMINI_API_KEY=<your-gemini-api-key>
COHERE_API_KEY=<your-cohere-api-key>

# Semantic Cache Settings
CACHE_ENABLED=true
CACHE_TTL=3600
SIMILARITY_THRESHOLD=0.95
```

4. Run the application:
```bash
python main.py
```

5. Run the pipeline (one-time setup):
```bash
python pipeline.py
```
This will process your documents, extract entities and relationships, and populate both Neo4j and Qdrant.

### Docker Setup

1. Build and run with Docker Compose:
```bash
cd GraphRAGDocker
docker-compose up -d
```

## Usage

### Running the Frontend

After completing the installation and running the pipeline, you can start using the GraphRAG system through the Streamlit interface:

1. **Start the Backend API**:
```bash
uvicorn main:app --host 0.0.0.0 --port 8001 --reload
```

2. **Launch the Streamlit Frontend** (in a new terminal):
```bash
cd frontend
streamlit run app.py
```
The frontend interface will open automatically in your browser at `http://localhost:8501`

### Frontend Features

The Streamlit interface provides:

- **Query Interface**: Enter your questions in natural language (English or Arabic)
- **Real-time Responses**: Stream responses as they're generated by the LLM
- **Context Visualization**: View the retrieved context from the knowledge graph
- **Source Attribution**: See which entities and relationships were used to generate the answer
- **Search Results**: Display hybrid search results from Qdrant
- **Document Management**: Upload and manage documents for processing
- **Settings Panel**: Configure search parameters and LLM settings
- **Arabic Medical Queries**: Ask questions about diseases, symptoms, and treatments in Arabic

### Example Workflow

1. Open the Streamlit interface at `http://localhost:8501`
2. Enter your question in the query box (English or Arabic)
   - Example (English): "What are the symptoms of diabetes?"
   - Example (Arabic): "ما هي أعراض مرض السكري؟"
3. The system will:
   - Check the semantic cache for similar previous queries
   - Perform hybrid search in Qdrant if needed
   - Retrieve relevant context from Neo4j graph
   - Generate a response using Gemini/Cohere
   - Display the answer with source attribution
4. View the retrieved context and sources used for the answer

### Arabic Medical Data

The system includes comprehensive medical information in Arabic covering:

- **Diseases** (الأمراض): Names, descriptions, and classifications
- **Symptoms** (الأعراض): Disease symptoms and manifestations
- **Treatments** (العلاجات): Treatment options and medications
- **Medications** (الأدوية): Drug names and usage information
- **Relationships**: Connections between diseases, symptoms, and treatments

**Example Arabic Queries**:
- "ما هي أعراض مرض الضغط؟" (What are the symptoms of hypertension?)
- "كيف يتم علاج السكري؟" (How is diabetes treated?)
- "ما هي الأدوية المستخدمة لعلاج الربو؟" (What medications are used to treat asthma?)

## Configuration

The application uses a settings management system located in `helpers.get_settings()`. Key configuration options include:

- Neo4j connection settings (URI, credentials)
- Qdrant vector database configuration
- LLM provider settings (Gemini, Cohere)
- Semantic cache configuration
- Hybrid search parameters
- Logging levels

### Qdrant Hybrid Search

The system implements hybrid search combining:
- **Dense Vectors**: Semantic embeddings for conceptual similarity (works excellently with Arabic)
- **Sparse Vectors**: Keyword-based matching for precise retrieval
- **Fusion Strategy**: Combines both approaches for optimal results

### Semantic Caching

Semantic caching reduces latency and API costs by:
- Storing previous query-response pairs with embeddings
- Matching similar queries using vector similarity (supports Arabic queries)
- Returning cached responses for semantically similar questions
- Configurable similarity thresholds and TTL

### LLM Integration

**Google Gemini**:
- Used for advanced reasoning and content generation
- Supports multimodal inputs
- Multilingual support including Arabic
- Configured via `GEMINI_API_KEY`

**Cohere**:
- Provides powerful embeddings and reranking
- Excellent for multilingual support (100+ languages including Arabic)
- High-quality Arabic text understanding
- Configured via `COHERE_API_KEY`

## Architecture

### Data Pipeline (`pipeline.py`)

The pipeline is a **one-time execution process** designed for initial data ingestion and processing:

1. **Entity Extraction**: Extracts entities from input documents (including Arabic medical texts) using LLMs (Gemini/Cohere)
2. **Relationship Extraction**: Identifies and extracts relationships between entities
3. **Neo4j Storage**: Stores entities and relationships as a knowledge graph in Neo4j
4. **Vector Embedding**: Generates embeddings for entities and relationships (multilingual embeddings for Arabic)
5. **Qdrant Injection**: Indexes embeddings in Qdrant for hybrid search capabilities

**Pipeline Flow**:
```
Input Documents (Arabic/English) → Entity/Relationship Extraction → Neo4j Graph Storage → Vector Embeddings → Qdrant Index
```

Once the pipeline completes, your data is:
- **Structured** in Neo4j as a knowledge graph
- **Searchable** via Qdrant with hybrid vector search
- **Ready** for RAG queries through the API endpoints in Arabic or English

**Note**: The pipeline should only be run once during initial setup or when adding new data to the knowledge base.

The application exposes RESTful API endpoints through controllers for querying the knowledge base:

- **NLP Controller**: Natural language processing and query operations against the knowledge graph (supports Arabic)
- **Process Controller**: Data processing and management operations

**How it works after pipeline execution**:
1. User sends a query via Streamlit frontend or API (in Arabic or English)
2. System checks semantic cache for similar queries
3. If not cached, performs hybrid search in Qdrant
4. Retrieves relevant context from Neo4j graph
5. Generates response using LLMs (Gemini/Cohere)
6. Caches the response for future similar queries
7. Returns response to user through the frontend

## Components

### Frontend (Streamlit)
Interactive web interface that provides:
- User-friendly query interface for asking questions in Arabic or English
- Real-time response streaming from the RAG system
- Visualization of search results and retrieved context
- Document upload and management
- Configuration settings management

### Pipeline
**One-time execution script** that:
- Extracts entities and relationships from documents using LLMs (supports Arabic medical texts)
- Builds a knowledge graph in Neo4j
- Creates vector embeddings and indexes them in Qdrant
- Should be run only during initial setup or data updates

### Controllers
Handle API requests and orchestrate business logic between models and storage layers.

### Models
Define data structures and interactions with Neo4j graph database using the Neo4jModel.

### Stores
Manage different storage backends:
- **LLM**: Factory pattern for various language model providers (Gemini, Cohere with Arabic support)
- **VectorDB**: Qdrant vector database operations with hybrid search capabilities
- **Templates**: Dynamic template parsing and rendering
- **Semantic Cache**: Intelligent caching layer for query optimization

### Helpers
Utility functions for configuration management, logging, and common operations.

## Development

### Running in Development Mode

```bash
python main.py --dev
```

### Logging

The application uses Python's built-in logging with configurable levels:

```python
import logging
logging.basicConfig(level=logging.INFO)
```

### Adding New Medical Data in Arabic

To add more Arabic medical data to the system:

1. Prepare your medical documents in Arabic (PDF, TXT, or other supported formats)
2. Place them in the appropriate data directory
3. Run the pipeline to process the new data:
```bash
python pipeline.py
```
4. The system will extract entities, relationships, and create embeddings for the new Arabic content

## Acknowledgments

- Neo4j for graph database capabilities
- Qdrant for high-performance vector search
- Google Gemini for advanced LLM capabilities with multilingual support
- Cohere for embeddings and excellent multilingual support (including Arabic)
- AsyncIO for Python async support
- The open-source community for various dependencies

## Support

For issues, questions, or contributions, please open an issue in the repository.

---

**Note**: Make sure to configure all necessary environment variables and API keys before running the application. The system is optimized for Arabic medical queries through Cohere's multilingual capabilities.